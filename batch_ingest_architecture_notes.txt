

# 🧾 Debug & Architecture Evolution Diary — *fraudmini Event-Driven Pipeline*

## ⚙️ Context

I built a **serverless ingestion pipeline** on AWS where uploading a CSV to S3 should automatically trigger a chain of Lambdas:

```
S3 (RawEventsBucket)
   → SQS (RawEventsQueue)
       → Lambda: BatchIngest
           → SQS (TransactionsQueue)
               → Lambda: ScoreFunction
```

Each stage processes data asynchronously — the goal was to parse CSVs, validate transactions, push them through scoring logic, and store receipts in a separate `RefinedEventsBucket`.

---

## 🩸 First Attempt – Direct S3 → Lambda Trigger

### What I tried

Initially, I wanted S3 to directly trigger **BatchIngestFunction** whenever I uploaded a CSV file under `inbox/`.

**Flow I aimed for:**

1. Upload CSV → triggers BatchIngest.
2. BatchIngest reads the CSV from the same bucket.
3. It processes records, creates a receipt JSON, moves the file to `/processed/`, and sends transactions directly to **ScoreFunction**.

### What went wrong

* I hit **circular dependency errors** because both the bucket and the Lambda referenced each other.
* The Lambda was both *triggered by* and *writing to* the same bucket — meaning every write operation could re-trigger itself.
* CloudFormation failed due to the dependency loop (`BucketPolicy ↔ LambdaRole ↔ Function`).
* The design was fragile and not scalable — one large CSV could flood concurrent Lambda invocations.

So I abandoned the direct-trigger idea.

---

## 💡 Second Design – Two Queues (RawEvents + Transactions)

I re-architected everything around two queues to fully decouple ingestion from scoring:

```
S3 (RawEventsBucket)
   → SQS (RawEventsQueue)
       → Lambda (BatchIngest)
           → SQS (TransactionsQueue)
               → Lambda (ScoreFunction)
```

This new design separated ingestion, processing, and scoring.
It also solved the circular dependency and gave me natural buffering and retries via SQS.

---

## 🧩 Debug Journey (Chronological)

### 1️⃣ Setting up S3 → SQS notification

I added this section to connect my raw bucket to the first queue:

```yaml
NotificationConfiguration:
  QueueConfigurations:
    - Event: s3:ObjectCreated:*
      Queue: !GetAtt RawEventsQueue.Arn
      Filter:
        S3Key:
          Rules:
            - Name: prefix
              Value: inbox/
            - Name: suffix
              Value: .csv
```

**Problem:**
Deployment failed with messages like:

> “Destination is not valid”
> “Unable to validate destination ARN”

I tried adding `DependsOn`, but that caused circular dependencies again.
CloudFormation couldn’t resolve the order because both resources referenced each other.

---

### 2️⃣ Understanding the root cause

I discovered that when S3 configures an event destination, it doesn’t just store the ARN — it actually *sends a test message* to the target SQS queue to verify permissions.
Since my queue was **KMS-encrypted**, S3 also needed to use the KMS key to generate and encrypt that test message.

At that point, my queue had this property:

```yaml
KmsMasterKeyId: !Ref AppDataKey
```

but my KMS key policy didn’t allow S3 to call `kms:GenerateDataKey` or `kms:Decrypt`.
So validation failed.

---

### 3️⃣ Fixing the KMS permissions

I realized S3 needed explicit access to use my CMK.
The right policy statement looked like this:

```yaml
- Sid: AllowS3ToUseKey
  Effect: Allow
  Principal:
    Service: s3.amazonaws.com
  Action:
    - kms:GenerateDataKey
    - kms:Decrypt
  Resource: "*"
  Condition:
    StringEquals:
      aws:SourceAccount: !Sub ${AWS::AccountId}
```

Once I added this, CloudFormation was finally able to create the notification configuration successfully.

---

### 4️⃣ The mysterious “test messages”

When deployment finally succeeded, my **BatchIngest Lambda** started receiving unexpected SQS messages like:

```json
{
  "Service": "Amazon S3",
  "Event": "s3:TestEvent",
  "Time": "...",
  "Bucket": "...",
  "RequestId": "...",
  "HostId": "..."
}
```

These weren’t real uploads.
They were *S3’s validation test events* — automatically sent every time a notification is created or updated.

My Lambda crashed with:

> `Invalid event structure: missing 'Records'`

So I added a guard clause to skip these messages:

```python
if "Records" not in s3_event:
    continue
```

After that, my Lambda started processing real upload events correctly.

---

### 5️⃣ Fixing the queue policy

Even with permissions fixed, I still needed to explicitly allow S3 to send messages to the queue.
I added the following **QueuePolicy**:

```yaml
RawEventsQueuePolicy:
  Type: AWS::SQS::QueuePolicy
  Properties:
    Queues:
      - !Ref RawEventsQueue
    PolicyDocument:
      Version: "2012-10-17"
      Statement:
        - Sid: AllowS3SendMessage
          Effect: Allow
          Principal: { Service: "s3.amazonaws.com" }
          Action: "sqs:SendMessage"
          Resource: !GetAtt RawEventsQueue.Arn
          Condition:
            ArnLike:
              aws:SourceArn: !Sub arn:aws:s3:::${RawEventsBucket}
            StringEquals:
              aws:SourceAccount: !Sub ${AWS::AccountId}
```

Those two conditions were the key:

* `ArnLike` restricts messages to my specific bucket.
* `SourceAccount` ensures they come only from my AWS account.

Without these, S3’s test events were “accepted” but real events were rejected.
After adding this, I started getting real S3 notifications containing `"Records"`.

---

### 6️⃣ Verifying the Lambda triggers

I also learned that the **`Events`** section under each Lambda behaves differently depending on what’s triggering it.
For example:

* `Type: SQS` → expects `Queue` and `BatchSize`.
* `Type: S3` → expects `Bucket`, `Events`, and `Filter`.
* `Type: Api` → expects `Path` and `Method`.

That helped me understand why earlier my Lambda wasn’t being triggered — I had mismatched properties under `Events:`.

---

## ✅ Final Working Architecture

```
S3 (RawEventsBucket)
  → SQS (RawEventsQueue)
    → Lambda: BatchIngest
      → SQS (TransactionsQueue)
        → Lambda: ScoreFunction
```

**Flow:**

1. I upload a CSV under `RawEventsBucket/inbox/`.
2. S3 sends an event to `RawEventsQueue`.
3. `BatchIngest` consumes it, downloads the CSV, validates rows, sends each transaction to `TransactionsQueue`, and writes receipts + processed files to `RefinedEventsBucket`.
4. `ScoreFunction` consumes messages from `TransactionsQueue`, scores them, writes to DynamoDB, and publishes alerts to SNS.

**Security and reliability layers:**

* All buckets and queues KMS-encrypted.
* Explicit KMS permissions for S3, SQS, and Lambda.
* IAM roles with least privilege.
* QueuePolicy linking S3 → SQS.
* HTTPS-only bucket policies.
* Separate buckets (`Raw` vs `Refined`) to prevent re-triggering.

---

## 🧠 Lessons I Learned

1. **S3 validates destinations** by sending a test message when configuring notifications.
   If the queue is KMS-encrypted, S3 needs `kms:GenerateDataKey` and `kms:Decrypt` permissions.

2. **QueuePolicy is mandatory** — without it, S3 cannot publish events even if the KMS permissions are right.

3. **`ArnLike` and `SourceAccount`** are required to make S3 events pass validation and prevent cross-account issues.

4. **CloudFormation circular dependencies** occur when a resource both references and modifies another that depends on it.
   I avoided this by separating roles and using queues as decoupling layers.

5. **SAM `Events` syntax changes** with each trigger type — understanding this saved me hours.

6. **S3 → SQS → Lambda** fan-out pattern is much more reliable than direct triggers.
   It absorbs traffic spikes and gives me retries, isolation, and buffering.

7. **Always check test messages** — not every event in SQS is real data. S3 test events must be filtered out.

---

## 🏁 Final Status

✅ Deployment successful
✅ Uploads trigger ingestion automatically
✅ BatchIngest parses and forwards transactions
✅ ScoreFunction executes risk logic and publishes alerts
✅ Receipts and processed files land in RefinedEventsBucket
✅ Full encryption, no recursion, clean logs



     ┌──────────────────────────┐
     │   RawEventsBucket (S3)   │
     │  inbox/*.csv uploads     │
     └─────────────┬────────────┘
                   │  Event Notification
                   ▼
     ┌──────────────────────────┐
     │  RawEventsQueue (SQS)    │
     │  Encrypted w/ AppDataKey │
     └─────────────┬────────────┘
                   │  Trigger
                   ▼
     ┌──────────────────────────┐
     │ BatchIngestFunction      │
     │  - Reads CSVs            │
     │  - Sends txns → SQS      │
     │  - Writes receipts       │
     │  - Moves files to        │
     │    RefinedEventsBucket   │
     └─────────────┬────────────┘
                   │
                   ▼
     ┌──────────────────────────┐
     │ TransactionsQueue (SQS)  │
     └─────────────┬────────────┘
                   │ Trigger
                   ▼
     ┌──────────────────────────┐
     │ ScoreFunction (Lambda)   │
     │ - Scores transactions    │
     │ - Writes results to      │
     │   DynamoDB               │
     │ - Publishes alerts → SNS │
     └─────────────┬────────────┘
                   │
                   ▼
     ┌──────────────────────────┐
     │ RefinedEventsBucket (S3) │
     │ - Receipts & processed   │
     │   files                  │
     └──────────────────────────┘

             │
             ▼
     ┌──────────────────────────┐
     │ AlertsTopic (SNS)        │
     │ - High-risk notifications│
     └──────────────────────────┘

-----------------------------------------------------------------------------------


                    ┌─────────────────────────────┐
                    │     fraudmini system        │
                    └─────────────────────────────┘
                                   │
                                   ▼
┌────────────────────────────────────────────────────────┐
│                1. RawEventsBucket (S3)                 │
│  - KMS-encrypted with AppDataKey                       │
│  - Event: ObjectCreated:* on inbox/*.csv               │
│  - Sends notification to RawEventsQueue (SQS)          │
│                                                        │
│  BucketPolicy:                                         │
│    - Deny insecure transport                           │
│    - Enforce KMS encryption on PUT                     │
│                                                        │
│  KMS Policy:                                           │
│    - Allows S3 to GenerateDataKey + Decrypt            │
│                                                        │
└────────────────────────────────────────────────────────┘
                                   │
                                   │  (S3 → SQS Notification)
                                   ▼
┌────────────────────────────────────────────────────────┐
│                2. RawEventsQueue (SQS)                 │
│  - KMS-encrypted (AppDataKey)                          │
│  - QueuePolicy allows S3:s3.amazonaws.com to SendMessage│
│    only from RawEventsBucket ARN + same AWS account     │
│                                                        │
│  Event Source for: BatchIngest Lambda                  │
└────────────────────────────────────────────────────────┘
                                   │
                                   │  (SQS → Lambda trigger)
                                   ▼
┌────────────────────────────────────────────────────────┐
│                3. BatchIngestFunction (Lambda)         │
│  - Reads events from RawEventsQueue                    │
│  - Downloads CSV from RawEventsBucket                  │
│  - Validates & parses records                          │
│  - Sends each record → TransactionsQueue (SQS)         │
│  - Writes receipts + copies to RefinedEventsBucket     │
│  - Deletes processed CSV from RawEventsBucket          │
│                                                        │
│  IAM Policy:                                           │
│    - s3:GetObject/DeleteObject on RawEventsBucket      │
│    - s3:PutObject on RefinedEventsBucket               │
│    - sqs:SendMessage on TransactionsQueue              │
│    - kms:Encrypt/Decrypt on AppDataKey                 │
└────────────────────────────────────────────────────────┘
                                   │
                                   │  (SQS → Lambda trigger)
                                   ▼
┌────────────────────────────────────────────────────────┐
│                4. TransactionsQueue (SQS)              │
│  - Buffers parsed transactions                         │
│  - Event Source for ScoreFunction                      │
└────────────────────────────────────────────────────────┘
                                   │
                                   │  (SQS → Lambda trigger)
                                   ▼
┌────────────────────────────────────────────────────────┐
│                5. ScoreFunction (Lambda)               │
│  - Processes transaction messages                      │
│  - Evaluates fraud/risk logic                          │
│  - Writes results to DynamoDB Tables                   │
│  - Publishes alerts to AlertsTopic (SNS)               │
│  - Uses AppDataKey for encryption/decryption            │
└────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌────────────────────────────────────────────────────────┐
│                6. RefinedEventsBucket (S3)             │
│  - Receipts (.json) and processed copies (.csv)        │
│  - KMS-encrypted with AppDataKey                       │
│  - Not part of trigger chain → prevents recursion      │
└────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌────────────────────────────────────────────────────────┐
│                7. AlertsTopic (SNS)                    │
│  - Receives high-risk alerts from ScoreFunction        │
│  - Can later fan-out to email/SMS notifications        │
└────────────────────────────────────────────────────────┘
